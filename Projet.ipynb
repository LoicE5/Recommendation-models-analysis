{"cells":[{"cell_type":"markdown","metadata":{"id":"9uFHHoXVQdlr"},"source":["# Data\n","- movie_ratings_500_id.pkl contains the interactions between users and movies\n","- movie_metadata.pkl contains detailed information about movies, e.g. genres, actors and directors of the movies.\n","\n","# Goal\n","- Compare the performances of different recommender systems\n","- Construct your own recommender systems\n"]},{"cell_type":"markdown","metadata":{"id":"Ns0mocTlUIqj"},"source":["# Baselines\n","\n","## User-Based Collaborative Filtering\n","This approach predicts $\\hat{r}_{(u,i)}$ by leveraging the ratings given to $i$ by $u$'s similar users. Formally, it is written as:\n","\n","\\begin{equation}\n","\\hat{r}_{(u,i)} = \\frac{\\sum\\limits_{v \\in \\mathcal{N}_i(u)}sim_{(u,v)}r_{vi}}{\\sum\\limits_{v \\in \\mathbf{N}_i(u)}|sim_{(u,v)}|}\n","\\end{equation}\n","where $sim_{(u,v)}$ is the similarity between user $u$ and $v$. Usually, $sim_{(u,v)}$ can be computed by Pearson Correlation or Cosine Similarity.\n","\n","## Item-Based Collaborative Filtering\n","This approach exploits the ratings given to similar items by the target user. The idea is formalized as follows:\n","\n","\\begin{equation}\n","\\hat{r}_{(u,i)} = \\frac{\\sum\\limits_{j \\in \\mathcal{N}_u(i)}sim_{(i,j)}r_{ui}}{\\sum\\limits_{j \\in \\mathbf{N}_u(i)}|sim_{(i,j)}|}\n","\\end{equation}\n","where $sim_{(i,j)}$ is the similarity between item $i$ and $j$. Usually, $sim_{(i,j)}$ can be computed by Pearson Correlation or Cosine Similarity.\n","\n","## Vanilla MF\n","Vanilla MF is the inner product of vectors that represent users and items. Each user is represented by a vector $\\textbf{p}_u \\in \\mathbb{R}^d$, each item is represented by a vector $\\textbf{q}_i \\in \\mathbb{R}^d$, and $\\hat{r}_{(u,i)}$ is computed by the inner product of $\\textbf{p}_u $ and $\\textbf{q}_i$. The core idea of Vanilla MF is depicted in the followng figure and follows the idea of SVD as we have seen during the TD.\n","\n","![picture](https://drive.google.com/uc?export=view&id=1EAG31Qw9Ti6hB7VqdONUlijWd4rXVobC)\n","\n","\\begin{equation}\n","\\hat{r}_{(u,i)} = \\textbf{p}_u{\\textbf{q}_i}^T\n","\\end{equation}\n","\n","## Some variants of SVD\n","\n","\n","-  SVD with bias: $\\hat{r_{ui}} = \\mu + b_u + b_i + {q_i}^Tp_u$\n","- SVD ++: $\\hat{r_{ui}} = \\mu + b_u + b_i + {q_i}^T(p_u + |I_u|^{\\frac{-1}{2}}\\sum\\limits_{j \\in I_u}y_j)$\n","\n","## Factorization machine (FM)\n","\n","FM takes into account user-item interactions and other features, such as users' contexts and items' attributes. It captures the second-order interactions of the vectors representing these features , thereby enriching FM's expressiveness. However, interactions involving less relevant features may introduce noise, as all interactions share the same weight. e.g. You may use FM to consider the features of items.\n","\n","\\begin{equation}\n","\\hat{y}_{FM}(\\textbf{X}) = w_0 + \\sum\\limits_{j =1}^nw_jx_j + \\sum\\limits_{j=1}^n\\sum\\limits_{k=j+1}^n\\textbf{v}_j^T\\textbf{v}_kx_jx_k\n","\\end{equation}\n","\n","where $\\textbf{X} \\in \\mathbb{R}^n$ is the feature vector, $n$ denotes the number of features, $w_0$ is the global bias, $w_j$ is the bias of the $j$-th feature and $\\textbf{v}_j^T\\textbf{v}_k$ denotes the bias of interaction between $j$-th feature and $k$-th feature, $\\textbf{v}_j \\in \\mathbb{R}^d$ is the vector representing $j$-th feature.\n","\n","## MLP\n","\n","You may also represent users and items by vectors and them feed them into a MLP to make prediction.\n","\n","## Metrics\n","\n","- $\\begin{equation}\n","RMSE = \\sqrt{\\frac{1}{|\\mathcal{T}|}\\sum\\limits_{(u,i)\\in\\mathcal{T}}{(\\hat{r}_{(u,i)}-r_{ui})}^2}\n","\\end{equation}$\n","\n","- $\\begin{equation}\n","MAE = \\frac{1}{|\\mathcal{T}|}\\sum\\limits_{(u,i)\\in\\mathcal{T}}{|\\hat{r}_{(u,i)}-r_{ui}|}\n","\\end{equation}$\n","-  Bonnus: you may also consider NDCG and HR under the top-k setting\n"]},{"cell_type":"markdown","metadata":{"id":"-zkYT8SQcFwj"},"source":["# Requirements\n","- Try to compare different methods that you have adopted and interpret the results that you have obtained\n","- Minizing the RMSE and MAE\n","- Construct a recommender system that returns the top 10 movies *that the user have not viewed yet*."]},{"cell_type":"markdown","metadata":{},"source":["# Our work\n","\n","## Step 1 : Import the data"]},{"cell_type":"markdown","metadata":{},"source":["We create a class Data with several methods. The goal here is to centralize the data processing to obtain the relevant dataframes we need to process our data with scikit surprise."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Hjg9-HjDT6Sz"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_rating</th>\n","      <th>user_id</th>\n","      <th>movie_id</th>\n","      <th>director</th>\n","      <th>genre</th>\n","      <th>actors</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>1380819</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>185150</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>1351377</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>386143</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>2173336</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>259813</th>\n","      <td>5</td>\n","      <td>1139877</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259814</th>\n","      <td>4</td>\n","      <td>1460015</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259815</th>\n","      <td>5</td>\n","      <td>1098265</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259816</th>\n","      <td>4</td>\n","      <td>1962894</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259817</th>\n","      <td>3</td>\n","      <td>2599245</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>259818 rows × 7 columns</p>\n","</div>"],"text/plain":["       user_rating  user_id   movie_id       director           genre  \\\n","0                4  1380819  tt0305224    Peter Segal          Comedy   \n","1                3   185150  tt0305224    Peter Segal          Comedy   \n","2                4  1351377  tt0305224    Peter Segal          Comedy   \n","3                2   386143  tt0305224    Peter Segal          Comedy   \n","4                3  2173336  tt0305224    Peter Segal          Comedy   \n","...            ...      ...        ...            ...             ...   \n","259813           5  1139877  tt0361862  Brad Anderson  Drama,Thriller   \n","259814           4  1460015  tt0361862  Brad Anderson  Drama,Thriller   \n","259815           5  1098265  tt0361862  Brad Anderson  Drama,Thriller   \n","259816           4  1962894  tt0361862  Brad Anderson  Drama,Thriller   \n","259817           3  2599245  tt0361862  Brad Anderson  Drama,Thriller   \n","\n","                                                   actors             title  \n","0       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","1       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","2       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","3       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","4       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","...                                                   ...               ...  \n","259813  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259814  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259815  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259816  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259817  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","\n","[259818 rows x 7 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","class Data:\n","\n","    metadata:dict\n","    ratings:dict\n","    user_ratings:dict\n","    ratings_df:pd.DataFrame\n","    metadata_df:pd.DataFrame\n","    merged_df:pd.DataFrame\n","    \n","    def __init__(self, metadata_path:str, ratings_path:str):\n","        self.metadata = pd.read_pickle(metadata_path)\n","        self.ratings = pd.read_pickle(ratings_path)\n","        self.user_ratings = self.get_user_ratings()\n","        self.ratings_df = self.get_ratings_as_df()\n","        self.metadata_df = self.get_metadata_as_df()\n","        self.merged_df = pd.merge(self.ratings_df, self.metadata_df, left_on='movie_id', right_on='movie_id')\n","\n","    def get_user_ratings(self)->dict:\n","        output = {}\n","        for k, array in self.ratings.items():\n","            for v in array:\n","                user_movie = {\n","                    'user_rating': int(v['user_rating']),\n","                    'movie_id': k\n","                }\n","                user_id = v['user_id']\n","\n","                if user_id in output.keys():\n","                    output[int(user_id)].append(user_movie)\n","                else:\n","                    output[int(user_id)] = [user_movie]\n","        return output\n","\n","    def get_ratings_as_df(self)->pd.DataFrame:\n","        output = []\n","\n","        for film, rating in self.ratings.items():\n","            for index in rating:\n","                index['movie_id'] = film\n","                del index['user_rating_date']\n","                output.append(index)\n","    \n","        return pd.DataFrame(output)\n","    \n","    def get_metadata_as_df(self)->pd.DataFrame:\n","        output = []\n","\n","        for movie_id, movie_data in self.metadata.items():\n","            movie_data['genre'] = \",\".join(movie_data['genre'])\n","            movie_data['actors'] = \",\".join(movie_data['actors'])\n","            output.append({'movie_id': movie_id, **movie_data})\n","\n","        return pd.DataFrame(output)\n","    \n","data = Data(\n","    metadata_path='movie_metadata.pkl', \n","    ratings_path='movie_ratings_500_id.pkl'\n",")\n","\n","data.merged_df"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2 : Obtain the movies that a user haven't viewed yet"]},{"cell_type":"markdown","metadata":{},"source":["## Creation of a base recommender class\n","Out goal is to create a base class that implements 3 methods : train, test and evaluate. Train will be overidden by a superclass (one for each recommender we want to put on the bench). Test and evaluate may or may not be overidden depending on the context. It features several attributes that are useful when it comes to train a model with the data we've got earlier."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from surprise import AlgoBase, Dataset, Prediction, Reader\n","from surprise.model_selection import train_test_split\n","from surprise import accuracy\n","\n","# We first create a class that will be used as a base to all the other recommender class we will create\n","\n","class BaseRecommender:\n","    model_data:Dataset\n","    df:pd.DataFrame\n","    train_set:Dataset\n","    test_set:Dataset\n","    model:AlgoBase\n","    predictions:list[Prediction]\n","\n","    def __init__(\n","        self, \n","        df:pd.DataFrame=data.merged_df[['user_id', 'movie_id', 'user_rating']], \n","        test_size:float=0.2, \n","        random_state:int=42\n","    ):\n","        self.df = df\n","        self.model_data = Dataset.load_from_df(df, Reader(rating_scale=(1, 5)))\n","        self.train_set, self.test_set = train_test_split(self.model_data, test_size=test_size, random_state=random_state)\n","\n","    def train(self)->None:\n","        pass\n","\n","    def test(self, update:bool=True)->list[Prediction]:\n","        predictions = self.model.test(self.test_set)\n","        if update:\n","            self.predictions = predictions\n","        return predictions\n","    \n","    def predict(self, user_id: int | str, item_id: str) -> float:\n","        if isinstance(user_id, int):\n","            user_id = str(user_id)\n","\n","        user_movie_rating = self.df[\n","            (self.df['user_id'] == user_id) & (self.df['movie_id'] == item_id)\n","        ]\n","\n","        if not user_movie_rating.empty:\n","            actual_rating = user_movie_rating['user_rating'].values[0]\n","            return float(actual_rating)\n","        else:\n","            return self.model.predict(user_id, item_id).est\n","    \n","    def get_top_movies_for_user(self, user_id: int | str, n: int = 10) -> pd.DataFrame:\n","        if isinstance(user_id, int):\n","            user_id = str(user_id)\n","\n","        # Get the list of movies the user has already watched\n","        watched_movies = set(self.df[self.df['user_id'] == int(user_id)]['movie_id'])\n","\n","        # Generate predictions for all movies in the dataset\n","        all_movies = set(self.df['movie_id'])\n","        candidate_movies = list(all_movies - watched_movies)\n","        predictions = [(user_id, movie_id, self.model.predict(user_id, movie_id).est) for movie_id in candidate_movies]\n","\n","        # Sort the predictions by estimated rating in descending order\n","        sorted_predictions = sorted(predictions, key=lambda x: x[2], reverse=True)\n","\n","        # Select the top N movies\n","        top_n_movies = sorted_predictions[:n]\n","\n","        # Create a DataFrame with the results\n","        result_df = pd.DataFrame(top_n_movies, columns=['user_id', 'movie_id', 'estimated_rating'])\n","\n","        return result_df\n","    \n","    def evaluate(self)->pd.DataFrame:\n","        assert self.predictions is not None\n","        assert len(self.predictions) >= 0\n","        return pd.DataFrame([{\n","            'model': self.__class__.__name__,\n","            'rmse': accuracy.rmse(self.predictions, verbose=False),\n","            'mae': accuracy.mae(self.predictions, verbose=False)\n","        }])\n"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis of several models and parameters"]},{"cell_type":"markdown","metadata":{},"source":["1. User-based collaborative filtering\n","   - With cosine\n","   - With Pearson\n","2. Item-based collaborative filtering\n","   - With cosine\n","   - With Pearson\n","\n","We use the KNNBasic model for this approach as it is the most relevant model for Collaborative filtering. Its native supports of cosine/pearson and user/item base as parameters makes it a relevant choice when calculating metrics.\n","\n","In order to integrate the full array of data points we have at our disposal, we provide the model with two similarity functions with a goal to leverage directors, genres and actors in the process. It is worth noting that the two latter, when they are plural, have been comma-joined in a single string. The usage of isin() as showcased in the above-mentioned functions is relevant because of the presence of all the data in one field, giving a simpler similiraty analysis than another table with joins or similars."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>rmse</th>\n","      <th>mae</th>\n","      <th>Similarity method</th>\n","      <th>User or Item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.038282</td>\n","      <td>0.831683</td>\n","      <td>Cosine</td>\n","      <td>User</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.042457</td>\n","      <td>0.836095</td>\n","      <td>Pearson</td>\n","      <td>User</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.032445</td>\n","      <td>0.808388</td>\n","      <td>Cosine</td>\n","      <td>Item</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.033257</td>\n","      <td>0.808883</td>\n","      <td>Pearson</td>\n","      <td>Item</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model      rmse       mae Similarity method User or Item\n","0  CollaborativeFiltering  1.038282  0.831683            Cosine         User\n","1  CollaborativeFiltering  1.042457  0.836095           Pearson         User\n","2  CollaborativeFiltering  1.032445  0.808388            Cosine         Item\n","3  CollaborativeFiltering  1.033257  0.808883           Pearson         Item"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from surprise import KNNBasic\n","# We create and instanciate a first recommender system with the User-Based or Item-based Collaborative Filtering method\n","\n","class CollaborativeFiltering(BaseRecommender):\n","    model:KNNBasic\n","    similarity_method:str\n","    user_based:bool\n","\n","    def __init__(self, user_based:bool=True, similarity_method:str='cosine'):\n","        super().__init__()\n","        self.similarity_method = similarity_method\n","        self.user_based = user_based\n","\n","    def train(self)->None:\n","        sim_options = {\n","            'name': self.similarity_method,\n","            'user_based': self.user_based,\n","            'user_custom_similarity': self.user_similarity_function if self.user_based else self.item_similarity_function\n","        }\n","        knn = KNNBasic(\n","            verbose=False,\n","            sim_options=sim_options\n","        )\n","        knn.fit(self.train_set)\n","        self.model = knn\n","\n","    def evaluate(self) -> pd.DataFrame:\n","        output_df = super().evaluate()\n","        output_df['Similarity method'] = self.similarity_method.capitalize()\n","        output_df['User or Item'] = 'User' if self.user_based else 'Item'\n","        return output_df\n","\n","    def user_similarity_function(user1:pd.DataFrame, user2:pd.DataFrame, metadata_df:pd.DataFrame)->int:\n","        # Compare directors, genres, and actors\n","        common_director = metadata_df[\n","            metadata_df['movie_id'].isin(user1['movie_id'])\n","        ]['director'].isin(\n","            metadata_df[\n","                metadata_df['movie_id'].isin(user2['movie_id'])\n","            ]['director']\n","        ).sum()\n","        \n","        common_genre = metadata_df[\n","            metadata_df['movie_id'].isin(user1['movie_id'])\n","        ]['genre'].isin(\n","            metadata_df[\n","                metadata_df['movie_id'].isin(user2['movie_id'])\n","        ]['genre']).sum()\n","        \n","        common_actors = metadata_df[\n","            metadata_df['movie_id'].isin(user1['movie_id'])\n","        ]['actors'].isin(\n","            metadata_df[\n","                metadata_df['movie_id'].isin(user2['movie_id'])\n","        ]['actors']).sum()\n","\n","        total_common = common_director + common_genre + common_actors\n","\n","        # Return a similarity score\n","        return total_common\n","\n","    def item_similarity_function(item1:pd.DataFrame, item2:pd.DataFrame, metadata_df:pd.DataFrame)->int:\n","        # Compare directors, genres, and actors\n","        common_director = metadata_df[metadata_df['movie_id'].isin([item1, item2])]['director'].nunique()\n","        common_genre = metadata_df[metadata_df['movie_id'].isin([item1, item2])]['genre'].nunique()\n","        common_actors = metadata_df[metadata_df['movie_id'].isin([item1, item2])]['actors'].nunique()\n","\n","        total_common = common_director + common_genre + common_actors\n","\n","        # Return a similarity score\n","        return total_common\n","\n","cosine_user_based_collaborative_filtering = CollaborativeFiltering(user_based=True, similarity_method='cosine')\n","cosine_user_based_collaborative_filtering.train()\n","cosine_user_based_collaborative_filtering.test()\n","\n","pearson_user_based_collaborative_filtering = CollaborativeFiltering(user_based=True, similarity_method='pearson')\n","pearson_user_based_collaborative_filtering.train()\n","pearson_user_based_collaborative_filtering.test()\n","\n","cosine_item_based_collaborative_filtering = CollaborativeFiltering(user_based=False, similarity_method='cosine')\n","cosine_item_based_collaborative_filtering.train()\n","cosine_item_based_collaborative_filtering.test()\n","\n","pearson_item_based_collaborative_filtering = CollaborativeFiltering(user_based=False, similarity_method='pearson')\n","pearson_item_based_collaborative_filtering.train()\n","pearson_item_based_collaborative_filtering.test()\n","\n","pd.concat([\n","    cosine_user_based_collaborative_filtering.evaluate(),\n","    pearson_user_based_collaborative_filtering.evaluate(),\n","    cosine_item_based_collaborative_filtering.evaluate(),\n","    pearson_item_based_collaborative_filtering.evaluate()\n","], ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["3. VanillaMF\n","4. SVD with bias\n","5. SVD++\n","\n","The three algorithms are based on the Matrix Factorization principle as highlighted in [Surprise's documentation](https://surprise.readthedocs.io/en/stable/matrix_factorization.html). The main inconvenience of these algorithms from our point of view lies in the absence of incorporation of the metadata in the recommendation process, given the only columns taken are the user's id, the item's id and the tuple's rating. This is a constraint inherent from Dataset.load_from_df() method that only accept these parameters, in this order, as explained in the method's docstring.\n","\n","Therefore, our approach is to build a second recommender base for the Matrix Factorization principle enabling an effective construction of these three models having much in common.\n","\n","We use random_state=True because we found out that this parameter overalls reduces the MAE & RMSE independently of the other parameters. The recommender can be fined-tuned with n_factors & n_epochs that are directly forwarded to the NMF model."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>rmse</th>\n","      <th>mae</th>\n","      <th>Factors</th>\n","      <th>Epochs</th>\n","      <th>Biased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>VanillaMF</td>\n","      <td>1.015985</td>\n","      <td>0.796611</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>SVDBias</td>\n","      <td>0.974461</td>\n","      <td>0.764493</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>SVDPlusPlus</td>\n","      <td>0.986530</td>\n","      <td>0.771494</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         model      rmse       mae  Factors  Epochs Biased\n","0    VanillaMF  1.015985  0.796611       15      50     No\n","0      SVDBias  0.974461  0.764493       15      50    Yes\n","0  SVDPlusPlus  0.986530  0.771494       15      50     No"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from pandas.core.api import DataFrame as DataFrame\n","from surprise import NMF, SVD, SVDpp\n","\n","class MatrixFactorization(BaseRecommender):\n","    model:NMF|SVD|SVDpp\n","    n_factors:int\n","    n_epochs:int\n","    biased:bool\n","\n","    def __init__(self, n_factors:int=15,n_epochs:int=50, biased:bool=False):\n","        super().__init__()\n","        self.n_factors = n_factors\n","        self.n_epochs = n_epochs\n","        self.biased = biased\n","\n","    def train(self)->None:\n","        pass\n","    \n","    def evaluate(self) -> DataFrame:\n","        output_df = super().evaluate()\n","        output_df['Factors'] = self.n_factors\n","        output_df['Epochs'] = self.n_epochs\n","        output_df['Biased'] = 'Yes' if self.biased else 'No'\n","        return output_df\n","\n","class VanillaMF(MatrixFactorization):\n","    model:NMF\n","\n","    def train(self)->None:\n","        nmf = NMF(\n","            n_factors=self.n_factors,\n","            n_epochs=self.n_epochs,\n","            biased=self.biased,\n","            random_state=True\n","        )\n","        nmf.fit(self.train_set)\n","        self.model = nmf\n","\n","class SVDBias(MatrixFactorization):\n","    model:SVD\n","\n","    def __init__(self, n_factors:int=15, n_epochs:int=50):\n","        super().__init__(n_factors,n_epochs, biased=True)\n","\n","    def train(self)->None:\n","        svd = SVD(\n","            n_factors=self.n_factors,\n","            n_epochs=self.n_epochs,\n","            biased=self.biased,\n","            random_state=True\n","        )\n","        svd.fit(self.train_set)\n","        self.model = svd\n","\n","class SVDPlusPlus(MatrixFactorization):\n","    model:SVDpp\n","\n","    def train(self)->None:\n","        svdpp = SVDpp(\n","            n_factors=self.n_factors,\n","            n_epochs=self.n_epochs,\n","            random_state=True\n","        )\n","        svdpp.fit(self.train_set)\n","        self.model = svdpp\n","\n","vanilla_mf = VanillaMF()\n","vanilla_mf.train()\n","vanilla_mf.test()\n","\n","svd_with_bias = SVDBias()\n","svd_with_bias.train()\n","svd_with_bias.test()\n","\n","svd_plus_plus = SVDPlusPlus()\n","svd_plus_plus.train()\n","svd_plus_plus.test()\n","\n","pd.concat([\n","    vanilla_mf.evaluate(),\n","    svd_with_bias.evaluate(),\n","    svd_plus_plus.evaluate()\n","])"]},{"cell_type":"markdown","metadata":{},"source":["## Building our own recommender\n","\n","We will be using our base class RecommenderBase combined with the AlgoBase Surprise's class possibilities.\n","For this, we would like to leverage the jaccard distance between each tuple of the dataset.\n","\n","Our approach is divided in two steps :\n","1. Building a model based on Surprise's Algobase class\n","2. Creating a recommender with our previous BaseRecommender class and use our new Jaccard-based model as a class variable like previously done.\n","\n","To achieve this, we will design a first class that will simply calculate the jaccard distance between rows containing only user_id, movie_id and user_rating.\n","\n","Then we will provide an ehnancement to include the metadata (director, actors, genres) in the process in order to have a more complete predicter."]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>rmse</th>\n","      <th>mae</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>JaccardRecommender</td>\n","      <td>1.089952</td>\n","      <td>0.900084</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                model      rmse       mae\n","0  JaccardRecommender  1.089952  0.900084"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["from typing import Any\n","import numpy as np\n","from surprise import AlgoBase, PredictionImpossible, Trainset\n","from sklearn.metrics import jaccard_score\n","from torch import cosine_similarity\n","\n","class JaccardDistanceAlgorithm(AlgoBase):\n","    def __init__(self, sim_options:dict={}, **kwargs:Any):\n","        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n","\n","    def fit(self, trainset:Trainset)->'JaccardDistanceAlgorithm':\n","        AlgoBase.fit(self, trainset)\n","        return self\n","\n","    def calculate_jaccard_similarity(self, rated_items_i:set, rated_items_other:set)->float:\n","        return len(rated_items_i.intersection(rated_items_other)) / len(rated_items_i.union(rated_items_other))\n","    \n","    def estimate(self, u: int | str, i: str) -> float:\n","        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n","            # If the user or item is not in the training_set\n","            return self.default_prediction()\n","\n","        user_ratings = set([item_id for item_id, _ in self.trainset.ur[u]])\n","\n","        # Check if the user has rated any items\n","        if not user_ratings:\n","            return self.default_prediction()\n","\n","        # Check if the user has rated the current item\n","        if i not in user_ratings:\n","            return self.default_prediction()\n","\n","        # Calculate Jaccard similarity-based prediction\n","        numerator = 0.0\n","        denominator = 0.0\n","\n","        for other_item, _ in self.trainset.ur[u]:\n","            # Check if the user has rated both the current item (i) and the other item\n","            if self.trainset.knows_item(i) and self.trainset.knows_item(other_item):\n","                try:\n","                    # Get the set of items rated by the user for the current item and the other item\n","                    rated_items_i = set([item_id for item_id, _ in self.trainset.ir[i]])\n","                    rated_items_other = set([item_id for item_id, _ in self.trainset.ir[other_item]])\n","\n","                    # Calculate Jaccard similarity\n","                    jaccard_similarity = self.calculate_jaccard_similarity(rated_items_i, rated_items_other)\n","\n","                    # Retrieve the rating for the other item from the user's ratings\n","                    rating_other = next((rating for item_id, rating in self.trainset.ur[u] if item_id == other_item), None)\n","\n","                    if rating_other is not None:\n","                        # Weighted sum of similarity and rating\n","                        numerator += rating_other * jaccard_similarity\n","                        denominator += jaccard_similarity\n","                except KeyError:\n","                    return self.default_prediction()                    \n","\n","        if denominator == 0:\n","            # If no similarity found\n","            return self.default_prediction()\n","\n","        return numerator / denominator\n","    \n","class JaccardRecommender(BaseRecommender):\n","    model:JaccardDistanceAlgorithm\n","\n","    def train(self)->None:\n","        jda = JaccardDistanceAlgorithm()\n","        jda.fit(self.train_set)\n","        self.model = jda\n","\n","jaccard_recommender = JaccardRecommender()\n","jaccard_recommender.train()\n","jaccard_recommender.test()\n","jaccard_recommender.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["To enhance the class performance, we've integrated metadata into the fit and estimate processes. The shift in logic involves adopting a linear kernel and employing a similarity matrix to compute the Jaccard score. This modification aims for improved efficiency and better results in terms of Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). Additionally, we leverage vectorization to optimize the computational process."]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>rmse</th>\n","      <th>mae</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>JaccardRecommenderWithMetadata</td>\n","      <td>1.089952</td>\n","      <td>0.900084</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            model      rmse       mae\n","0  JaccardRecommenderWithMetadata  1.089952  0.900084"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["from surprise import AlgoBase\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","\n","class EnhancedJaccardAlgorithm(AlgoBase):\n","    vectorizer:TfidfVectorizer\n","\n","    def __init__(self, sim_options:dict={}, **kwargs:Any):\n","        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n","        self.vectorizer = TfidfVectorizer()\n","\n","    def fit(self, trainset:Trainset)->'EnhancedJaccardAlgorithm':\n","        AlgoBase.fit(self, trainset)\n","\n","        user_features = self.extract_features(trainset.ur)\n","        item_features = self.extract_features(trainset.ir, include_features=True)\n","\n","        tfidf_matrix = self.vectorizer.fit_transform(user_features + item_features)\n","\n","        self.similarity_matrix = linear_kernel(tfidf_matrix)\n","\n","        return self\n","\n","    def extract_features(self, rating_matrix:dict, include_features:bool=False)->list:\n","        feature_list = []\n","        for _, ratings in rating_matrix.items():\n","            features = [\n","                f\"{movie_id}_{self.get_movie_features(movie_id, include_features)}\"\n","                for movie_id, _ in ratings\n","            ]\n","            feature_list.append(\" \".join(features))\n","        return feature_list\n","\n","    def get_movie_features(self, movie_id:str, include_features:bool=False)->str:\n","        if include_features:\n","            return f\"director_{movie_id} actors_{movie_id} genres_{movie_id}\"\n","        return f\"{movie_id}\"\n","\n","    def estimate(self, u:int|str, i:str)->float:\n","        try:\n","            u_id = self.trainset.to_inner_uid(u)\n","            i_id = self.trainset.to_inner_iid(i)\n","        except ValueError:\n","            u_id = \"UKN__\" + str(u)\n","            i_id = \"UKN__\" + str(i)\n","\n","\n","        if i_id not in self.trainset.ir.keys():\n","            return self.default_prediction()\n","\n","        jaccard_similarity = self.similarity_matrix[u_id, i_id]\n","\n","        estimated_rating = jaccard_similarity * 4 + 1\n","\n","        return estimated_rating\n","\n","class JaccardRecommenderWithMetadata(BaseRecommender):\n","    model:EnhancedJaccardAlgorithm\n","\n","    def train(self)->None:\n","        eja = EnhancedJaccardAlgorithm()\n","        eja.fit(self.train_set)\n","        self.model = eja\n","\n","jaccard_recommender_with_metadata = JaccardRecommenderWithMetadata()\n","jaccard_recommender_with_metadata.train()\n","jaccard_recommender_with_metadata.test()\n","jaccard_recommender_with_metadata.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["## Overall performance\n","\n","Our analysis have stated that, with default parameters and without proceeding with fine-tuning, the algorithms that performs the best according to the MAE & RMSE metrics are :\n","\n","| Recommender                                    | RMSE     | MAE      | Rank |\n","|------------------------------------------------|----------|----------|------|\n","| SVD with bias                                  | 0.974461 | 0.764493 | 1    |\n","| SVD++                                          | 0.986530 | 0.771494 | 2    |\n","| Vanilla MF                                     | 1.015985 | 0.796611 | 3    |\n","| Cosine item-based collaborative filtering      | 1.032445 | 0.808388 | 4    |\n","| Pearson item-based collaborative filtering     | 1.033257 | 0.808883 | 5    |\n","| Cosine user-based collaborative filtering      | 1.038282 | 0.831683 | 6    |\n","| Pearson user-based collaborative filtering     | 1.042457 | 0.836095 | 7    |\n","| Jaccard distance (custom recommender)          | 1.130819 | 0.86635  | 8    |\n","| Enhanced Jaccard distance (custom recommender) | 1.130819 | 0.86635  | 8    |\n","\n","Those results demonstrates that, purely metrics speaking, out commitment to incorporate the metadata of the movies (genres, actors & director) in the process have been lacking of relevance. We had the opportunity to incorporate those data twice : In the collaborative filtering recommenders (thanks to the similarity functions) and in the Enhanced Jaccard distance custom recommender (thanks to the vectorization & linear kernel). In both cases, the recommenders performed worse than the matrix-factorization-based ones that did not require this extra data to function.\n","\n","In the context of a work project, provided that the results of the model are meaningful and matches the problematic we solve, we would advocate for the use of such a system."]},{"cell_type":"markdown","metadata":{},"source":["## Some recommendations\n","\n","We will pick one user in the dataset, then give him/her the top 10 movies he/she haven't viewed yet (and should).\n","This process will be done with every recommender to evaluate the homogenity of the results."]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["========== Jaccard Recommender ==========\n","  user_id   movie_id                 title  estimated_rating\n","0  386143  tt0128853       You've Got Mail          4.009853\n","1  386143  tt0276751           About a Boy          4.009656\n","2  386143  tt0405159   Million Dollar Baby          4.009028\n","3  386143  tt0286499  Bend It Like Beckham          4.005535\n","4  386143  tt0313737      Two Weeks Notice          4.003213\n","5  386143  tt0375679                 Crash          4.000894\n","6  386143  tt0314331         Love Actually          3.999959\n","7  386143  tt0372784         Batman Begins          3.998302\n","8  386143  tt0256415    Sweet Home Alabama          3.993716\n","9  386143  tt0268978      A Beautiful Mind          3.989106\n","\n","\n"]}],"source":["user = 386143\n","\n","def show_top_10_movies(user:int,recommender:BaseRecommender, name:str)->None:\n","    if name:\n","        print(f'========== {name} ==========')\n","    print(pd.merge(recommender.get_top_movies_for_user(user, 10), data.metadata_df, on='movie_id')[['user_id','movie_id','title','estimated_rating']])\n","    print('\\n')\n","\n","# show_top_10_movies(user, svd_with_bias, 'SVD with bias')\n","# show_top_10_movies(user, svd_plus_plus, 'SVD++')\n","# show_top_10_movies(user, vanilla_mf, 'Vanilla MF')\n","# show_top_10_movies(user, cosine_item_based_collaborative_filtering, 'Cosine item-based collaborative filtering')\n","# show_top_10_movies(user, pearson_item_based_collaborative_filtering, 'Pearson item-based collaborative filtering')\n","# show_top_10_movies(user, cosine_user_based_collaborative_filtering, 'Cosine user-based collaborative filtering')\n","# show_top_10_movies(user, pearson_user_based_collaborative_filtering, 'Pearson user-based collaborative filtering')\n","show_top_10_movies(user, jaccard_recommender, 'Jaccard Recommender')\n","# show_top_10_movies(user, jaccard_recommender_with_metadata, 'Jaccard recommender with metadata')"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMECTqF1tFQ90lMJxoJ3/jC","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
