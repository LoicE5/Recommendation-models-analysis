{"cells":[{"cell_type":"markdown","metadata":{"id":"9uFHHoXVQdlr"},"source":["# Data\n","- movie_ratings_500_id.pkl contains the interactions between users and movies\n","- movie_metadata.pkl contains detailed information about movies, e.g. genres, actors and directors of the movies.\n","\n","# Goal\n","- Compare the performances of different recommender systems\n","- Construct your own recommender systems\n"]},{"cell_type":"markdown","metadata":{"id":"Ns0mocTlUIqj"},"source":["# Baselines\n","\n","## User-Based Collaborative Filtering\n","This approach predicts $\\hat{r}_{(u,i)}$ by leveraging the ratings given to $i$ by $u$'s similar users. Formally, it is written as:\n","\n","\\begin{equation}\n","\\hat{r}_{(u,i)} = \\frac{\\sum\\limits_{v \\in \\mathcal{N}_i(u)}sim_{(u,v)}r_{vi}}{\\sum\\limits_{v \\in \\mathbf{N}_i(u)}|sim_{(u,v)}|}\n","\\end{equation}\n","where $sim_{(u,v)}$ is the similarity between user $u$ and $v$. Usually, $sim_{(u,v)}$ can be computed by Pearson Correlation or Cosine Similarity.\n","\n","## Item-Based Collaborative Filtering\n","This approach exploits the ratings given to similar items by the target user. The idea is formalized as follows:\n","\n","\\begin{equation}\n","\\hat{r}_{(u,i)} = \\frac{\\sum\\limits_{j \\in \\mathcal{N}_u(i)}sim_{(i,j)}r_{ui}}{\\sum\\limits_{j \\in \\mathbf{N}_u(i)}|sim_{(i,j)}|}\n","\\end{equation}\n","where $sim_{(i,j)}$ is the similarity between item $i$ and $j$. Usually, $sim_{(i,j)}$ can be computed by Pearson Correlation or Cosine Similarity.\n","\n","## Vanilla MF\n","Vanilla MF is the inner product of vectors that represent users and items. Each user is represented by a vector $\\textbf{p}_u \\in \\mathbb{R}^d$, each item is represented by a vector $\\textbf{q}_i \\in \\mathbb{R}^d$, and $\\hat{r}_{(u,i)}$ is computed by the inner product of $\\textbf{p}_u $ and $\\textbf{q}_i$. The core idea of Vanilla MF is depicted in the followng figure and follows the idea of SVD as we have seen during the TD.\n","\n","![picture](https://drive.google.com/uc?export=view&id=1EAG31Qw9Ti6hB7VqdONUlijWd4rXVobC)\n","\n","\\begin{equation}\n","\\hat{r}_{(u,i)} = \\textbf{p}_u{\\textbf{q}_i}^T\n","\\end{equation}\n","\n","## Some variants of SVD\n","\n","\n","-  SVD with bias: $\\hat{r_{ui}} = \\mu + b_u + b_i + {q_i}^Tp_u$\n","- SVD ++: $\\hat{r_{ui}} = \\mu + b_u + b_i + {q_i}^T(p_u + |I_u|^{\\frac{-1}{2}}\\sum\\limits_{j \\in I_u}y_j)$\n","\n","## Factorization machine (FM)\n","\n","FM takes into account user-item interactions and other features, such as users' contexts and items' attributes. It captures the second-order interactions of the vectors representing these features , thereby enriching FM's expressiveness. However, interactions involving less relevant features may introduce noise, as all interactions share the same weight. e.g. You may use FM to consider the features of items.\n","\n","\\begin{equation}\n","\\hat{y}_{FM}(\\textbf{X}) = w_0 + \\sum\\limits_{j =1}^nw_jx_j + \\sum\\limits_{j=1}^n\\sum\\limits_{k=j+1}^n\\textbf{v}_j^T\\textbf{v}_kx_jx_k\n","\\end{equation}\n","\n","where $\\textbf{X} \\in \\mathbb{R}^n$ is the feature vector, $n$ denotes the number of features, $w_0$ is the global bias, $w_j$ is the bias of the $j$-th feature and $\\textbf{v}_j^T\\textbf{v}_k$ denotes the bias of interaction between $j$-th feature and $k$-th feature, $\\textbf{v}_j \\in \\mathbb{R}^d$ is the vector representing $j$-th feature.\n","\n","## MLP\n","\n","You may also represent users and items by vectors and them feed them into a MLP to make prediction.\n","\n","## Metrics\n","\n","- $\\begin{equation}\n","RMSE = \\sqrt{\\frac{1}{|\\mathcal{T}|}\\sum\\limits_{(u,i)\\in\\mathcal{T}}{(\\hat{r}_{(u,i)}-r_{ui})}^2}\n","\\end{equation}$\n","\n","- $\\begin{equation}\n","MAE = \\frac{1}{|\\mathcal{T}|}\\sum\\limits_{(u,i)\\in\\mathcal{T}}{|\\hat{r}_{(u,i)}-r_{ui}|}\n","\\end{equation}$\n","-  Bonnus: you may also consider NDCG and HR under the top-k setting\n"]},{"cell_type":"markdown","metadata":{"id":"-zkYT8SQcFwj"},"source":["# Requirements\n","- Try to compare different methods that you have adopted and interpret the results that you have obtained\n","- Minizing the RMSE and MAE\n","- Construct a recommender system that returns the top 10 movies *that the user have not viewed yet*."]},{"cell_type":"markdown","metadata":{},"source":["# Our work\n","\n","## Step 1 : Import the data"]},{"cell_type":"markdown","metadata":{},"source":["We create a class Data with several methods. The goal here is to centralize the data processing to obtain the relevant dataframes we need to process our data with scikit surprise."]},{"cell_type":"code","execution_count":108,"metadata":{"id":"Hjg9-HjDT6Sz"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_rating</th>\n","      <th>user_id</th>\n","      <th>movie_id</th>\n","      <th>director</th>\n","      <th>genre</th>\n","      <th>actors</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>1380819</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>185150</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>1351377</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>386143</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>2173336</td>\n","      <td>tt0305224</td>\n","      <td>Peter Segal</td>\n","      <td>Comedy</td>\n","      <td>Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...</td>\n","      <td>Anger Management</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>259813</th>\n","      <td>5</td>\n","      <td>1139877</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259814</th>\n","      <td>4</td>\n","      <td>1460015</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259815</th>\n","      <td>5</td>\n","      <td>1098265</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259816</th>\n","      <td>4</td>\n","      <td>1962894</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","    <tr>\n","      <th>259817</th>\n","      <td>3</td>\n","      <td>2599245</td>\n","      <td>tt0361862</td>\n","      <td>Brad Anderson</td>\n","      <td>Drama,Thriller</td>\n","      <td>Christian Bale,Jennifer Jason Leigh,Aitana Sán...</td>\n","      <td>The Machinist</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>259818 rows × 7 columns</p>\n","</div>"],"text/plain":["       user_rating  user_id   movie_id       director           genre  \\\n","0                4  1380819  tt0305224    Peter Segal          Comedy   \n","1                3   185150  tt0305224    Peter Segal          Comedy   \n","2                4  1351377  tt0305224    Peter Segal          Comedy   \n","3                2   386143  tt0305224    Peter Segal          Comedy   \n","4                3  2173336  tt0305224    Peter Segal          Comedy   \n","...            ...      ...        ...            ...             ...   \n","259813           5  1139877  tt0361862  Brad Anderson  Drama,Thriller   \n","259814           4  1460015  tt0361862  Brad Anderson  Drama,Thriller   \n","259815           5  1098265  tt0361862  Brad Anderson  Drama,Thriller   \n","259816           4  1962894  tt0361862  Brad Anderson  Drama,Thriller   \n","259817           3  2599245  tt0361862  Brad Anderson  Drama,Thriller   \n","\n","                                                   actors             title  \n","0       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","1       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","2       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","3       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","4       Jack Nicholson,Adam Sandler,Marisa Tomei,Woody...  Anger Management  \n","...                                                   ...               ...  \n","259813  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259814  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259815  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259816  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","259817  Christian Bale,Jennifer Jason Leigh,Aitana Sán...     The Machinist  \n","\n","[259818 rows x 7 columns]"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","class Data:\n","\n","    metadata:dict\n","    ratings:dict\n","    user_ratings:dict\n","    ratings_df:pd.DataFrame\n","    metadata_df:pd.DataFrame\n","    merged_df:pd.DataFrame\n","    \n","    def __init__(self, metadata_path:str, ratings_path:str):\n","        self.metadata = pd.read_pickle(metadata_path)\n","        self.ratings = pd.read_pickle(ratings_path)\n","        self.user_ratings = self.get_user_ratings()\n","        self.ratings_df = self.get_ratings_as_df()\n","        self.metadata_df = self.get_metadata_as_df()\n","        self.merged_df = pd.merge(self.ratings_df, self.metadata_df, left_on='movie_id', right_on='movie_id')\n","\n","    def get_user_ratings(self)->dict:\n","        output = {}\n","        for k, array in self.ratings.items():\n","            for v in array:\n","                user_movie = {\n","                    'user_rating': int(v['user_rating']),\n","                    'movie_id': k\n","                }\n","                user_id = v['user_id']\n","\n","                if user_id in output.keys():\n","                    output[int(user_id)].append(user_movie)\n","                else:\n","                    output[int(user_id)] = [user_movie]\n","        return output\n","\n","    def get_ratings_as_df(self)->pd.DataFrame:\n","        output = []\n","\n","        for film, rating in self.ratings.items():\n","            for index in rating:\n","                index['movie_id'] = film\n","                del index['user_rating_date']\n","                output.append(index)\n","    \n","        return pd.DataFrame(output)\n","    \n","    def get_metadata_as_df(self)->pd.DataFrame:\n","        output = []\n","\n","        for movie_id, movie_data in self.metadata.items():\n","            movie_data['genre'] = \",\".join(movie_data['genre'])\n","            movie_data['actors'] = \",\".join(movie_data['actors'])\n","            output.append({'movie_id': movie_id, **movie_data})\n","\n","        return pd.DataFrame(output)\n","    \n","data = Data(\n","    metadata_path='movie_metadata.pkl', \n","    ratings_path='movie_ratings_500_id.pkl'\n",")\n","\n","data.merged_df"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2 : Obtain the movies that a user haven't viewed yet"]},{"cell_type":"markdown","metadata":{},"source":["## Creation of a base recommender class\n","Out goal is to create a base class that implements 3 methods : train, test and evaluate. Train will be overidden by a superclass (one for each recommender we want to put on the bench). Test and evaluate may or may not be overidden depending on the context. It features several attributes that are useful when it comes to train a model with the data we've got earlier."]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":["from surprise import AlgoBase, Dataset, Prediction, Reader\n","from surprise.model_selection import train_test_split\n","from surprise import accuracy\n","\n","# We first create a class that will be used as a base to all the other recommender class we will create\n","\n","class BaseRecommender:\n","    model_data:Dataset\n","    df:pd.DataFrame\n","    train_set:Dataset\n","    test_set:Dataset\n","    model:AlgoBase\n","    predictions:list[Prediction]\n","\n","    def __init__(\n","        self, \n","        df:pd.DataFrame=data.merged_df[['user_id', 'movie_id', 'user_rating']], \n","        test_size:float=0.2, \n","        random_state:int=42\n","    ):\n","        self.df = df\n","        self.model_data = Dataset.load_from_df(df, Reader(rating_scale=(1, 5)))\n","        self.train_set, self.test_set = train_test_split(self.model_data, test_size=test_size, random_state=random_state)\n","\n","    def train(self)->None:\n","        pass\n","\n","    def test(self, update:bool=True)->list[Prediction]:\n","        predictions = self.model.test(self.test_set)\n","        if update:\n","            self.predictions = predictions\n","        return predictions\n","    \n","    def predict(self, user_id: int | str, item_id: str) -> float:\n","        if isinstance(user_id, int):\n","            user_id = str(user_id)\n","\n","        user_movie_rating = self.df[\n","            (self.df['user_id'] == user_id) & (self.df['movie_id'] == item_id)\n","        ]\n","\n","        if not user_movie_rating.empty:\n","            # User has rated the movie, return the actual rating\n","            actual_rating = user_movie_rating['user_rating'].values[0]\n","            return float(actual_rating)\n","        else:\n","            # User hasn't rated the movie, proceed with prediction\n","            return self.model.predict(user_id, item_id).est\n","    \n","    def get_top_movies_for_user(self, user_id: int | str, n: int = 10) -> pd.DataFrame:\n","        if isinstance(user_id, int):\n","            user_id = str(user_id)\n","\n","        # Get the list of movies the user has already watched\n","        watched_movies = set(self.df[self.df['user_id'] == int(user_id)]['movie_id'])\n","\n","        # Generate predictions for all movies in the dataset\n","        all_movies = set(self.df['movie_id'])\n","        candidate_movies = list(all_movies - watched_movies)\n","        predictions = [(user_id, movie_id, self.model.predict(user_id, movie_id).est) for movie_id in candidate_movies]\n","\n","        # Sort the predictions by estimated rating in descending order\n","        sorted_predictions = sorted(predictions, key=lambda x: x[2], reverse=True)\n","\n","        # Select the top N movies\n","        top_n_movies = sorted_predictions[:n]\n","\n","        # Create a DataFrame with the results\n","        result_df = pd.DataFrame(top_n_movies, columns=['user_id', 'movie_id', 'estimated_rating'])\n","\n","        return result_df\n","    \n","    def evaluate(self)->pd.DataFrame:\n","        assert self.predictions is not None\n","        assert len(self.predictions) >= 0\n","        return pd.DataFrame([{\n","            'model': self.__class__.__name__,\n","            'rmse': accuracy.rmse(self.predictions),\n","            'mae': accuracy.mae(self.predictions)\n","        }])\n"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis of several models and parameters"]},{"cell_type":"markdown","metadata":{},"source":["1. User-based collaborative filtering\n","   - With cosine\n","   - With Pearson\n","2. Item-based collaborative filtering\n","   - With cosine\n","   - With Pearson\n","\n","We use the KNNBasic model for this approach as it is the most relevant model for Collaborative filtering. Its native supports of cosine/pearson and user/item base as parameters makes it a relevant choice when calculating metrics.\n","\n","In order to integrate the full array of data points we have at our disposal, we provide the model with two similarity functions with a goal to leverage directors, genres and actors in the process. It is worth noting that the two latter, when they are plural, have been comma-joined in a single string. The usage of isin() as showcased in the above-mentioned functions is relevant because of the presence of all the data in one field, giving a simpler similiraty analysis than another table with joins or similars."]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the pearson similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the pearson similarity matrix...\n","Done computing similarity matrix.\n","RMSE: 1.0383\n","MAE:  0.8317\n","RMSE: 1.0425\n","MAE:  0.8361\n","RMSE: 1.0324\n","MAE:  0.8084\n","RMSE: 1.0333\n","MAE:  0.8089\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>rmse</th>\n","      <th>mae</th>\n","      <th>Similarity method</th>\n","      <th>User or Item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.038282</td>\n","      <td>0.831683</td>\n","      <td>Cosine</td>\n","      <td>User</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.042457</td>\n","      <td>0.836095</td>\n","      <td>Pearson</td>\n","      <td>User</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.032445</td>\n","      <td>0.808388</td>\n","      <td>Cosine</td>\n","      <td>Item</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CollaborativeFiltering</td>\n","      <td>1.033257</td>\n","      <td>0.808883</td>\n","      <td>Pearson</td>\n","      <td>Item</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    model      rmse       mae Similarity method User or Item\n","0  CollaborativeFiltering  1.038282  0.831683            Cosine         User\n","1  CollaborativeFiltering  1.042457  0.836095           Pearson         User\n","2  CollaborativeFiltering  1.032445  0.808388            Cosine         Item\n","3  CollaborativeFiltering  1.033257  0.808883           Pearson         Item"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["from surprise import KNNBasic\n","# We create and instanciate a first recommender system with the User-Based or Item-based Collaborative Filtering method\n","\n","class CollaborativeFiltering(BaseRecommender):\n","    model:KNNBasic\n","    similarity_method:str\n","    user_based:bool\n","\n","    def __init__(self, user_based:bool=True, similarity_method:str='cosine'):\n","        super().__init__()\n","        self.similarity_method = similarity_method\n","        self.user_based = user_based\n","\n","    def train(self)->None:\n","        sim_options = {\n","            'name': self.similarity_method, \n","            'user_based': self.user_based, \n","            'user_custom_similarity': self.user_similarity_function if self.user_based else self.item_similarity_function\n","        }\n","        knn = KNNBasic(sim_options=sim_options)\n","        knn.fit(self.train_set)\n","        self.model = knn\n","\n","    def evaluate(self) -> pd.DataFrame:\n","        output_df = super().evaluate()\n","        output_df['Similarity method'] = self.similarity_method.capitalize()\n","        output_df['User or Item'] = 'User' if self.user_based else 'Item'\n","        return output_df\n","\n","    def user_similarity_function(user1:pd.DataFrame, user2:pd.DataFrame, metadata_df:pd.DataFrame)->int:\n","        # Compare directors, genres, and actors\n","        common_director = metadata_df[\n","            metadata_df['movie_id'].isin(user1['movie_id'])\n","        ]['director'].isin(\n","            metadata_df[\n","                metadata_df['movie_id'].isin(user2['movie_id'])\n","            ]['director']\n","        ).sum()\n","        \n","        common_genre = metadata_df[\n","            metadata_df['movie_id'].isin(user1['movie_id'])\n","        ]['genre'].isin(\n","            metadata_df[\n","                metadata_df['movie_id'].isin(user2['movie_id'])\n","        ]['genre']).sum()\n","        \n","        common_actors = metadata_df[\n","            metadata_df['movie_id'].isin(user1['movie_id'])\n","        ]['actors'].isin(\n","            metadata_df[\n","                metadata_df['movie_id'].isin(user2['movie_id'])\n","        ]['actors']).sum()\n","\n","        total_common = common_director + common_genre + common_actors\n","\n","        # Return a similarity score\n","        return total_common\n","\n","    def item_similarity_function(item1:pd.DataFrame, item2:pd.DataFrame, metadata_df:pd.DataFrame)->int:\n","        # Compare directors, genres, and actors\n","        common_director = metadata_df[metadata_df['movie_id'].isin([item1, item2])]['director'].nunique()\n","        common_genre = metadata_df[metadata_df['movie_id'].isin([item1, item2])]['genre'].nunique()\n","        common_actors = metadata_df[metadata_df['movie_id'].isin([item1, item2])]['actors'].nunique()\n","\n","        total_common = common_director + common_genre + common_actors\n","\n","        # Return a similarity score\n","        return total_common\n","\n","cosine_user_based_collaborative_filtering = CollaborativeFiltering(user_based=True, similarity_method='cosine')\n","cosine_user_based_collaborative_filtering.train()\n","cosine_user_based_collaborative_filtering.test()\n","\n","pearson_user_based_collaborative_filtering = CollaborativeFiltering(user_based=True, similarity_method='pearson')\n","pearson_user_based_collaborative_filtering.train()\n","pearson_user_based_collaborative_filtering.test()\n","\n","cosine_item_based_collaborative_filtering = CollaborativeFiltering(user_based=False, similarity_method='cosine')\n","cosine_item_based_collaborative_filtering.train()\n","cosine_item_based_collaborative_filtering.test()\n","\n","pearson_item_based_collaborative_filtering = CollaborativeFiltering(user_based=False, similarity_method='pearson')\n","pearson_item_based_collaborative_filtering.train()\n","pearson_item_based_collaborative_filtering.test()\n","\n","pd.concat([\n","    cosine_user_based_collaborative_filtering.evaluate(),\n","    pearson_user_based_collaborative_filtering.evaluate(),\n","    cosine_item_based_collaborative_filtering.evaluate(),\n","    pearson_item_based_collaborative_filtering.evaluate()\n","], ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["3. VanillaMF\n","4. SVD with bias\n","5. SVD++\n","\n","The three algorithms are based on the Matrix Factorization principle as highlighted in [Surprise's documentation](https://surprise.readthedocs.io/en/stable/matrix_factorization.html). The main inconvenience of these algorithms from our point of view lies in the absence of incorporation of the metadata in the recommendation process, given the only columns taken are the user's id, the item's id and the tuple's rating. This is a constraint inherent from Dataset.load_from_df() method that only accept these parameters, in this order, as explained in the method's docstring.\n","\n","Therefore, our approach is to build a second recommender base for the Matrix Factorization principle enabling an effective construction of these three models having much in common.\n","\n","We use random_state=True because we found out that this parameter overalls reduces the MAE & RMSE independently of the other parameters. The recommender can be fined-tuned with n_factors & n_epochs that are directly forwarded to the NMF model."]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 1.0160\n","MAE:  0.7966\n","RMSE: 0.9745\n","MAE:  0.7645\n","RMSE: 0.9865\n","MAE:  0.7715\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>rmse</th>\n","      <th>mae</th>\n","      <th>Factors</th>\n","      <th>Epochs</th>\n","      <th>Biased</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>VanillaMF</td>\n","      <td>1.015985</td>\n","      <td>0.796611</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>SVDBias</td>\n","      <td>0.974461</td>\n","      <td>0.764493</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>SVDPlusPlus</td>\n","      <td>0.986530</td>\n","      <td>0.771494</td>\n","      <td>15</td>\n","      <td>50</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         model      rmse       mae  Factors  Epochs Biased\n","0    VanillaMF  1.015985  0.796611       15      50     No\n","0      SVDBias  0.974461  0.764493       15      50    Yes\n","0  SVDPlusPlus  0.986530  0.771494       15      50     No"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["from pandas.core.api import DataFrame as DataFrame\n","from surprise import NMF, SVD, SVDpp\n","\n","class MatrixFactorization(BaseRecommender):\n","    model:NMF|SVD|SVDpp\n","    n_factors:int\n","    n_epochs:int\n","    biased:bool\n","\n","    def __init__(self, n_factors:int=15,n_epochs:int=50, biased:bool=False):\n","        super().__init__()\n","        self.n_factors = n_factors\n","        self.n_epochs = n_epochs\n","        self.biased = biased\n","\n","    def train(self)->None:\n","        pass\n","    \n","    def evaluate(self) -> DataFrame:\n","        output_df = super().evaluate()\n","        output_df['Factors'] = self.n_factors\n","        output_df['Epochs'] = self.n_epochs\n","        output_df['Biased'] = 'Yes' if self.biased else 'No'\n","        return output_df\n","\n","class VanillaMF(MatrixFactorization):\n","    model:NMF\n","\n","    def train(self)->None:\n","        nmf = NMF(\n","            n_factors=self.n_factors,\n","            n_epochs=self.n_epochs,\n","            biased=self.biased,\n","            random_state=True\n","        )\n","        nmf.fit(self.train_set)\n","        self.model = nmf\n","\n","class SVDBias(MatrixFactorization):\n","    model:SVD\n","\n","    def __init__(self, n_factors:int=15, n_epochs:int=50):\n","        super().__init__(n_factors,n_epochs, biased=True)\n","\n","    def train(self)->None:\n","        svd = SVD(\n","            n_factors=self.n_factors,\n","            n_epochs=self.n_epochs,\n","            biased=self.biased,\n","            random_state=True\n","        )\n","        svd.fit(self.train_set)\n","        self.model = svd\n","\n","class SVDPlusPlus(MatrixFactorization):\n","    model:SVDpp\n","\n","    def train(self)->None:\n","        svdpp = SVDpp(\n","            n_factors=self.n_factors,\n","            n_epochs=self.n_epochs,\n","            random_state=True\n","        )\n","        svdpp.fit(self.train_set)\n","        self.model = svdpp\n","\n","vanilla_mf = VanillaMF()\n","vanilla_mf.train()\n","vanilla_mf.test()\n","\n","svd_with_bias = SVDBias()\n","svd_with_bias.train()\n","svd_with_bias.test()\n","\n","svd_plus_plus = SVDPlusPlus()\n","svd_plus_plus.train()\n","svd_plus_plus.test()\n","\n","pd.concat([\n","    vanilla_mf.evaluate(),\n","    svd_with_bias.evaluate(),\n","    svd_plus_plus.evaluate()\n","])"]},{"cell_type":"markdown","metadata":{},"source":["## Building our own recommender\n","\n","We will be using our base class RecommenderBase combined with the AlgoBase Surprise's class possibilities."]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE: 1.1360\n","MAE:  0.8732\n"]},{"data":{"text/plain":["0.8731737356631514"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from surprise import AlgoBase, Dataset, Reader\n","from surprise.model_selection import train_test_split\n","from sklearn.metrics import jaccard_score\n","\n","\n","# Assuming your dataset is in a variable named 'df'\n","# If not, replace 'df' with your actual variable name\n","reader = Reader(rating_scale=(1, 5))\n","current_data = Dataset.load_from_df(data.merged_df[['user_id', 'movie_id', 'user_rating']], reader)\n","trainset, testset = train_test_split(current_data, test_size=0.25)\n","\n","\n","class JaccardDistanceAlgorithm(AlgoBase):\n","    def __init__(self, sim_options={}, **kwargs):\n","        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n","\n","    def fit(self, trainset):\n","        AlgoBase.fit(self, trainset)\n","        return self\n","\n","    def estimate(self, u, i):\n","        # Retrieve the user and item ids\n","        try:\n","            u_id = self.trainset.to_inner_uid(u)\n","            i_id = self.trainset.to_inner_iid(i)\n","        except ValueError:\n","            # Handle the case where the user or item is not in the training set\n","            # You can return a default value or handle it as needed\n","            return 3.0  # Default rating\n","\n","        # Get the user and item vectors\n","        u_vector = self.trainset.ur[u_id]\n","        i_vector = self.trainset.ir[i_id]\n","\n","        # Compute Jaccard similarity between user and item vectors\n","        jaccard_similarity = jaccard_score(u_vector, i_vector)\n","\n","        # Estimate the rating based on the Jaccard similarity\n","        estimated_rating = jaccard_similarity * 4 + 1  # Scale the similarity to the rating scale (1 to 5)\n","\n","        return estimated_rating\n","\n","# Create an instance of your custom algorithm\n","jaccard_algo = JaccardDistanceAlgorithm()\n","\n","# Train the algorithm on the training set\n","jaccard_algo.fit(trainset)\n","\n","# Evaluate the algorithm on the test set\n","predictions = jaccard_algo.test(testset)\n","\n","# Print RMSE (Root Mean Squared Error) as an evaluation metric\n","from surprise import accuracy\n","accuracy.rmse(predictions)\n","accuracy.mae(predictions)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMECTqF1tFQ90lMJxoJ3/jC","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
